# AVC444 Deep Dive: Research and Implementation Analysis
**Date:** 2025-12-25
**Purpose:** Comprehensive research on AVC444 codec for premium feature development
**Scope:** History, specification, existing implementations, encoder requirements

---

## EXECUTIVE SUMMARY

**AVC444 = H.264 encoding with full 4:4:4 chroma resolution**

**Key Insight:** It's a **clever trick** to send YUV444 data using standard YUV420 H.264 encoders (which don't natively support 4:4:4).

**How It Works:** Pack YUV444 into **TWO YUV420 streams**:
- Stream 1: Full luma (Y) + subsampled chroma (Cb/Cr)
- Stream 2: Additional chroma data to reconstruct full 4:4:4

**Our Status:**
- ‚úÖ IronRDP has complete AVC444 **protocol support** (decoding + encoding PDUs)
- ‚úÖ We have `send_avc444_frame()` method ready to use
- ‚ùå We need to **implement the encoder** (create the two streams)

**Implementation Effort:** 24-34 hours (detailed plan below)

---

## HISTORICAL CONTEXT

### elmarco's Original Work (PR #648)

**Who:** Marc-Andre Lureau (@elmarco)
- Red Hat engineer
- QEMU/SPICE contributor
- Created https://github.com/elmarco/freerdp-rs

**PR #648 - "WIP: Add GFX ([MS-RDPEGFX]) support"**
- **Created:** Jan 28, 2025
- **Status:** Still OPEN, marked WIP
- **Content:** PDU parsing, DVC processing framework
- **Key Quote:** "I'd rather focus on AVC444 atm"
- **Your Interaction:** You commented Dec 16, offered to contribute server-side EGFX
- **His Response:** "feel free to close this PR once you have one that supersedes it"

**Outcome:** Your PR #1057 **supersedes** PR #648 with complete implementation

**Link:** https://github.com/Devolutions/IronRDP/pull/648

### Your PR #1057 Status

**PR #1057: "feat(egfx): add MS-RDPEGFX Graphics Pipeline Extension"**
- **Created:** Dec 16, 2025
- **Status:** OPEN, under review by CBenoit (Devolutions maintainer)
- **Size:** 6,265 lines, 32 files
- **Content:** Complete MS-RDPEGFX implementation
- **Includes:** Full AVC444 protocol support (PDUs, encoding, server methods)
- **Reviewer Feedback:** "Looking good overall, although I didn't review everything yet"
- **Last Update:** Dec 21, 2025

**What This Means:**
- ‚úÖ IronRDP will have complete AVC444 **protocol** support when PR merges
- ‚úÖ You can use it NOW from your fork
- ‚ùå We still need to implement the **encoder** (create the two H.264 streams)

**Link:** https://github.com/Devolutions/IronRDP/pull/1057

---

## MS-RDPEGFX SPECIFICATION ANALYSIS

### What is AVC444?

**Official Name:** "RFX_AVC444_BITMAP_STREAM"
**Specification:** [MS-RDPEGFX Section 2.2.4.5]
**Purpose:** H.264 encoding with full 4:4:4 chroma subsampling

**Comparison:**

| Feature | AVC420 | AVC444 |
|---------|--------|--------|
| Chroma Subsampling | 4:2:0 (quarter resolution) | 4:4:4 (full resolution) |
| Bits per Pixel | ~12 bits | ~24 bits |
| Color Accuracy | Good for video | Excellent for graphics |
| Bandwidth | Lower | ~30-40% higher |
| Use Case | General desktop, video | Graphics, CAD, photos |
| Encoder Complexity | Single stream | Dual stream |

### The Clever Trick: Packing YUV444 into Two YUV420 Streams

**The Problem:**
- H.264 encoders (OpenH264, x264) output YUV420 natively
- YUV420 discards 75% of chroma data (2√ó2 subsampling)
- YUV444 needs full chroma at every pixel
- How to send YUV444 using YUV420 encoder?

**Microsoft's Solution:**

```
YUV444 Frame (1920√ó1080)
    ‚Üì
Decompose into TWO YUV420 frames:

Stream 1 (Main/Luma View):
    Y: Full 1920√ó1080 luma
    U: Subsampled 960√ó540 chroma (from original YUV444)
    V: Subsampled 960√ó540 chroma

Stream 2 (Auxiliary/Chroma View):
    Y: Additional chroma as fake "luma"
    U: More chroma data as fake "U"
    V: More chroma data as fake "V"

Client Decoder:
    ‚Üê Receives two YUV420 bitstreams
    ‚Üê Combines them to reconstruct full YUV444
    ‚Üê Full color at every pixel!
```

**Why This Works:**
- H.264 encoder sees two normal YUV420 frames
- Encoder doesn't know it's encoding chroma as luma
- Client has special logic to recombine streams
- Result: Full 4:4:4 color using 4:2:0 encoder

**Specification References:**
- [RFX_AVC444_BITMAP_STREAM Structure](https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-rdpegfx/844018a5-d717-4bc9-bddb-8b4d6be5dd3f)
- [YUV420p Stream Combination for YUV444](https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-rdpegfx/8131c1bc-1af8-4907-a05a-f72f4581160f)

### Encoding Field (LC Bits)

**Stream Info (32 bits):**
- **Bits 0-29:** Size of stream1 in bytes
- **Bits 30-31:** LC (Luma/Chroma) field

**LC Values:**

| LC Value | Meaning | Streams Present |
|----------|---------|-----------------|
| **0x0** | LUMA_AND_CHROMA | stream1 = YUV420, stream2 = Chroma420 |
| **0x1** | LUMA | stream1 = YUV420, stream2 = empty (chroma deferred) |
| **0x2** | CHROMA | stream1 = Chroma420, stream2 = empty (use with previous luma) |
| **0x3** | Invalid | Must not occur |

**Common Pattern:**
- Frame 1: LC=0x0 (send both luma and chroma)
- Frame 2: LC=0x0 (send both again)
- Optimization: LC=0x1 (send luma only), LC=0x2 (send chroma separately)

**For Simplicity:** Always use LC=0x0 (send both streams every frame)

---

## FREERDP IMPLEMENTATION ANALYSIS

### FreeRDP's AVC444 Decoder (2016)

**Commit:** [5bc333c - Implemented GFX AVC444 support](https://github.com/FreeRDP/FreeRDP/commit/5bc333c626f1db493a2c2e3c49d91cc6fb145309)
**Author:** FreeRDP team
**Date:** March 2016

**Key Functions:**

```c
// Parse AVC444 bitstream
static int rdpgfx_decode_AVC444(RDPGFX_PLUGIN* gfx,
                                 RDPGFX_SURFACE_COMMAND* cmd) {
    // Read 32-bit header
    UINT32 tmp = Stream_Get_UINT32(s);
    UINT32 cbAvc420EncodedBitstream1 = tmp & 0x3FFFFFFFUL;  // Bits 0-29
    UINT32 LC = (tmp >> 30) & 0x03;  // Bits 30-31

    // Parse stream1 metablock
    if (!rdpgfx_read_h264_metablock(s, &meta1)) {
        return -1;
    }

    // If dual stream (LC == 0), parse stream2
    if (LC == 0) {
        if (!rdpgfx_read_h264_metablock(s, &meta2)) {
            return -1;
        }
    }

    // Invoke H.264 decoder for both streams
    // Decoder reconstructs YUV444
}
```

**Reconstruction Strategy:**

FreeRDP's decoder:
1. Decodes both H.264 bitstreams to YUV420
2. Applies **chroma filtering** to combine streams
3. Uses **reverse filter** with threshold=30 to avoid quantization artifacts
4. Reconstructs full YUV444 frame

**Algorithm (from FreeRDP issues):**
```
// For each 2√ó2 pixel block:
u_filtered = (u0 + u1 + u2 + u3) / 4
v_filtered = (v0 + v1 + v2 + v3) / 4

// Where u1, u2, u3, v1, v2, v3 come from auxiliary stream
```

**Issues Encountered:**
- [#11040](https://github.com/FreeRDP/FreeRDP/issues/11040): Reverse filter applied multiple times (bug)
- [#4030](https://github.com/FreeRDP/FreeRDP/issues/4030): Quality lower than Windows client
- [#6030](https://github.com/FreeRDP/FreeRDP/issues/6030): Massive artifacting with OpenH264

**Lessons Learned:**
- AVC444 decoder is complex (chroma reconstruction has edge cases)
- Quality depends on correct filter application
- OpenH264 can have issues (FFmpeg decoder preferred)

---

## IRONRDP CURRENT SUPPORT ANALYSIS

### What IronRDP Already Has (Your PR #1057)

**Protocol Layer - COMPLETE ‚úÖ**

**1. Avc444BitmapStream Structure:**
```rust
pub struct Avc444BitmapStream<'a> {
    pub encoding: Encoding,          // LC field (LUMA_AND_CHROMA, LUMA, CHROMA)
    pub stream1: Avc420BitmapStream<'a>,  // Primary YUV420 stream
    pub stream2: Option<Avc420BitmapStream<'a>>,  // Optional auxiliary stream
}
```

**2. Encoding Flags:**
```rust
bitflags! {
    pub struct Encoding: u8 {
        const LUMA = 0x00;            // LC = 0x1 (luma only)
        const CHROMA = 0x02;          // LC = 0x2 (chroma only)
        const LUMA_AND_CHROMA = 0x00; // LC = 0x0 (both streams)
    }
}
```

**3. Server Send Method - READY TO USE:**
```rust
pub fn send_avc444_frame(
    &mut self,
    surface_id: u16,
    luma_data: &[u8],              // Stream1 H.264 bitstream
    luma_regions: &[Avc420Region], // Regions for stream1
    chroma_data: Option<&[u8]>,    // Stream2 H.264 bitstream (optional)
    chroma_regions: Option<&[Avc420Region]>, // Regions for stream2
    timestamp_ms: u32,
) -> Option<u32>
```

**This method:**
- ‚úÖ Builds Avc444BitmapStream with both streams
- ‚úÖ Sets encoding flag correctly
- ‚úÖ Queues StartFrame/WireToSurface1/EndFrame
- ‚úÖ Ready to use once we provide the H.264 bitstreams

**Protocol Layer: 100% COMPLETE** - Ready to use!

### What We Need to Implement - ENCODER ‚ùå

**The Missing Piece:** Creating the two H.264 bitstreams from BGRA input

**Required Components:**

1. **Color Space Conversion:** BGRA ‚Üí YUV444
2. **Stream Decomposition:** YUV444 ‚Üí Two YUV420 frames
3. **Dual Encoding:** Encode both streams with OpenH264
4. **Bitstream Packaging:** Combine into Avc444BitmapStream

---

## AVC444 ENCODING: THE ALGORITHM

### Step-by-Step Encoding Process

**Input:** BGRA frame (1920√ó1080√ó4 bytes = 8,294,400 bytes)

**Output:** Two H.264 bitstreams that reconstruct to YUV444

#### **Step 1: BGRA to YUV444 Conversion**

```rust
// ITU-R BT.709 matrix (for HD content):
for each pixel (B, G, R, A):
    Y  =  0.2126*R + 0.7152*G + 0.0722*B
    U  = -0.1146*R - 0.3854*G + 0.5000*B + 128
    V  =  0.5000*R - 0.4542*G - 0.0458*B + 128

Result: Three planes at full resolution
    Y_444: 1920√ó1080 luma values
    U_444: 1920√ó1080 chroma U values
    V_444: 1920√ó1080 chroma V values
```

#### **Step 2: Decompose YUV444 into Two YUV420 Frames**

**Microsoft's Packing Strategy:**

```
Stream 1 (Main View - Luma + Subsampled Chroma):
    Y_plane: Use full Y_444 (1920√ó1080)
    U_plane: Subsample U_444 to 960√ó540 (2√ó2 box filter)
    V_plane: Subsample V_444 to 960√ó540 (2√ó2 box filter)

    ‚Üí Standard YUV420 frame (encoder sees normal input)

Stream 2 (Auxiliary View - Additional Chroma):
    Here's the trick - encode chroma data AS IF it were luma!

    Y_plane: Pack remaining U chroma data
    U_plane: Pack remaining V chroma data
    V_plane: Dummy data (not used)

    ‚Üí Looks like YUV420 to encoder, but contains chroma info
```

**Detailed Packing (16√ó16 Macroblock Level):**

Per [MS-RDPEGFX Section 3.3.8.3.2](https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-rdpegfx/8131c1bc-1af8-4907-a05a-f72f4581160f):

```
For each 16√ó16 macroblock in YUV444:

Main View Macroblock:
    Y[16√ó16]: Full luma from Y_444
    U[8√ó8]: Subsampled from U_444 (even rows, even cols)
    V[8√ó8]: Subsampled from V_444 (even rows, even cols)

Auxiliary View Macroblock:
    Y[16√ó16]: Pack U_444 odd samples (interleaved on 8-line basis)
    U[8√ó8]: Pack V_444 odd samples
    V[8√ó8]: Not used (or copy of U for encoder stability)

Client Reconstruction:
    For each pixel at (x, y):
        if x and y both even:
            U = from main view
            V = from main view
        else:
            U = from auxiliary view Y plane
            V = from auxiliary view U plane

    Apply optional reverse filter (threshold=30)
```

**Key Insight:** The auxiliary stream encodes the **missing 75% of chroma data** that YUV420 discards.

#### **Step 3: Encode Both Streams with H.264**

```rust
// Stream 1: Standard YUV420 encoding
let yuv420_main = YUV420 {
    y: Y_444,           // Full luma
    u: subsample(U_444),  // 2√ó2 subsample
    v: subsample(V_444),  // 2√ó2 subsample
};

let stream1_h264 = openh264_encode(yuv420_main)?;

// Stream 2: Pack chroma as fake luma
let yuv420_aux = YUV420 {
    y: pack_chroma_as_luma(U_444),  // Odd U samples as Y
    u: pack_chroma_as_chroma(V_444), // Odd V samples as U
    v: vec![128; size],  // Neutral chroma
};

let stream2_h264 = openh264_encode(yuv420_aux)?;
```

#### **Step 4: Package into AVC444 Structure**

```rust
let avc444_stream = Avc444BitmapStream {
    encoding: Encoding::LUMA_AND_CHROMA,  // LC = 0x0
    stream1: Avc420BitmapStream {
        rectangles: vec![full_screen_rect],
        quant_qual_vals: vec![QuantQuality { qp: 23, .. }],
        data: &stream1_h264,  // H.264 bitstream
    },
    stream2: Some(Avc420BitmapStream {
        rectangles: vec![full_screen_rect],
        quant_qual_vals: vec![QuantQuality { qp: 23, .. }],
        data: &stream2_h264,  // H.264 bitstream
    }),
};

// Send via IronRDP (already implemented!)
server.send_avc444_frame(...);
```

---

## IMPLEMENTATION CHALLENGES

### Challenge 1: Chroma Packing Algorithm

**The Complex Part:** How exactly to pack the auxiliary chroma data

**From Specification:**
> "Interleaved chrominance data on an 8-line basis"
> "Areas B1 to B7 make up the Y, U, and V planes"

**Interpretation (from FreeRDP code):**
- Main view: Standard 4:2:0 subsampling (every other pixel horizontally and vertically)
- Auxiliary view: Contains the **odd** pixels that were discarded
- Interleaving pattern: 8 lines of U data, then 8 lines of V data, repeat

**Algorithm (Simplified for Initial Implementation):**

```rust
// Main view: Take even pixels only
for y in (0..height).step_by(2) {
    for x in (0..width).step_by(2) {
        main_u[y/2][x/2] = U_444[y][x];  // Even rows, even cols
        main_v[y/2][x/2] = V_444[y][x];
    }
}

// Auxiliary view: Pack odd pixels as "luma"
let mut aux_y = vec![];
for y in 0..height {
    for x in 0..width {
        if x % 2 == 1 || y % 2 == 1 {  // At least one coordinate odd
            aux_y.push(U_444[y][x]);  // Pack as fake luma
        }
    }
}

// Similar for V data packed into aux U plane
```

**Complexity:** Medium-High
**Risk:** Pixel ordering must match spec exactly
**Testing:** Compare with Windows client decoder output

### Challenge 2: Encoder Configuration

**Issue:** OpenH264 expects valid YUV420 input

**For Stream 2 (Auxiliary):**
- Y plane contains chroma data (not actual luma)
- Encoder might optimize differently thinking it's luma
- Need to ensure encoder doesn't apply luma-specific optimizations

**Possible Solutions:**

**A. Lie to Encoder (Recommended):**
```rust
// Treat chroma data as if it were luma
// OpenH264 doesn't care - it just encodes bytes
// Works because H.264 processes Y/U/V independently
```

**B. Use Grayscale Mode:**
```rust
// Encode auxiliary stream as grayscale (Y only, dummy U/V)
// Simpler but wastes some bits on unused U/V planes
```

**C. Multiple Encoder Instances:**
```rust
// Separate encoder for main and auxiliary
// Allows different QP or other settings
// More memory but more control
```

**Recommendation:** Start with Option A (lie to encoder)

### Challenge 3: Bandwidth and CPU

**Bandwidth Impact:**
- AVC420 frame: ~20-30KB (single stream)
- AVC444 frame: ~26-40KB (dual streams, +30-40%)

**CPU Impact:**
- Encoding time: 2√ó (two H.264 encodes)
- Color conversion: 1.5√ó (more complex)
- Total: ~2.5√ó CPU usage vs AVC420

**Mitigation:**
- Use for graphics/CAD users who need quality
- Offer as premium "high-quality" mode
- Document bandwidth/CPU tradeoffs

### Challenge 4: Quality Validation

**How to Verify Correctness:**

1. **Color Accuracy Test:**
   - Display color gradients (RGB color picker)
   - Compare AVC420 vs AVC444
   - Should see smoother gradients in AVC444

2. **Text Rendering:**
   - Open text editor with colored text
   - AVC420: Slight color fringing
   - AVC444: Crisp color boundaries

3. **Graphics Applications:**
   - Open GIMP or Inkscape
   - Zoom into colored graphics
   - Verify no color shift or artifacts

4. **Comparison Tool:**
   - Capture screenshot via AVC420
   - Capture same content via AVC444
   - Pixel-by-pixel comparison
   - Measure color error (Delta-E)

**Success Criteria:**
- No color banding in gradients
- Sharp color transitions
- Accurate color reproduction (measured Delta-E < 5)
- No encoder crashes or artifacts

---

## DETAILED IMPLEMENTATION PLAN

### Phase 1: Color Conversion (6-8 hours)

**Create:** `src/egfx/color_conversion.rs`

**Task 1.1: BGRA to YUV444 Conversion** (3-4h)

```rust
/// Convert BGRA to YUV444 using ITU-R BT.709 (HD standard)
pub fn bgra_to_yuv444(
    bgra: &[u8],
    width: usize,
    height: usize,
) -> (Vec<u8>, Vec<u8>, Vec<u8>) {
    let pixel_count = width * height;
    let mut y = Vec::with_capacity(pixel_count);
    let mut u = Vec::with_capacity(pixel_count);
    let mut v = Vec::with_capacity(pixel_count);

    for i in 0..pixel_count {
        let b = bgra[i * 4] as f32;
        let g = bgra[i * 4 + 1] as f32;
        let r = bgra[i * 4 + 2] as f32;

        // BT.709 matrix
        let y_val = (0.2126 * r + 0.7152 * g + 0.0722 * b).clamp(0.0, 255.0);
        let u_val = (-0.1146 * r - 0.3854 * g + 0.5000 * b + 128.0).clamp(0.0, 255.0);
        let v_val = (0.5000 * r - 0.4542 * g - 0.0458 * b + 128.0).clamp(0.0, 255.0);

        y.push(y_val as u8);
        u.push(u_val as u8);
        v.push(v_val as u8);
    }

    (y, u, v)
}
```

**Task 1.2: YUV420 Subsampling** (1-2h)

```rust
/// Subsample YUV444 chroma to YUV420 (2√ó2 box filter)
pub fn subsample_chroma_420(
    chroma_444: &[u8],
    width: usize,
    height: usize,
) -> Vec<u8> {
    let out_width = width / 2;
    let out_height = height / 2;
    let mut chroma_420 = Vec::with_capacity(out_width * out_height);

    for y in (0..height).step_by(2) {
        for x in (0..width).step_by(2) {
            // 2√ó2 box filter (average 4 pixels)
            let idx00 = y * width + x;
            let idx01 = y * width + (x + 1);
            let idx10 = (y + 1) * width + x;
            let idx11 = (y + 1) * width + (x + 1);

            let avg = (chroma_444[idx00] as u32
                     + chroma_444[idx01] as u32
                     + chroma_444[idx10] as u32
                     + chroma_444[idx11] as u32) / 4;

            chroma_420.push(avg as u8);
        }
    }

    chroma_420
}
```

**Task 1.3: Testing** (2-3h)
- Unit tests for conversion
- Verify BT.709 matrix correctness
- Test with known RGB values
- Compare output with reference implementation

### Phase 2: Stream Decomposition (8-12 hours)

**Create:** `src/egfx/avc444_packing.rs`

**Task 2.1: Main View (Luma Stream)** (2-3h)

```rust
/// Create main YUV420 view (full luma + subsampled chroma)
pub fn create_main_view(
    y_444: &[u8],
    u_444: &[u8],
    v_444: &[u8],
    width: usize,
    height: usize,
) -> YUV420Frame {
    YUV420Frame {
        y: y_444.to_vec(),  // Full luma at original resolution
        u: subsample_chroma_420(u_444, width, height),  // Subsample U
        v: subsample_chroma_420(v_444, width, height),  // Subsample V
        width,
        height,
    }
}
```

**Task 2.2: Auxiliary View (Chroma Stream)** (4-6h)

**COMPLEX - This is the tricky part:**

```rust
/// Create auxiliary YUV420 view (chroma data as fake luma)
///
/// Packs the missing 75% of chroma data (odd pixels) into
/// a second YUV420 frame for transmission.
pub fn create_auxiliary_view(
    u_444: &[u8],
    v_444: &[u8],
    width: usize,
    height: usize,
) -> YUV420Frame {
    // Pack odd U samples as Y plane
    // Pack odd V samples as U plane
    // V plane = neutral (128)

    // TODO: Implement exact MS-RDPEGFX packing algorithm
    // See section 3.3.8.3.2 for macroblock-level details

    // Simplified approach for initial implementation:
    let mut aux_y = Vec::new();
    let mut aux_u = Vec::new();

    // Extract odd pixels from U and V
    for y in 0..height {
        for x in 0..width {
            if x % 2 == 1 || y % 2 == 1 {
                aux_y.push(u_444[y * width + x]);
                aux_u.push(v_444[y * width + x]);
            }
        }
    }

    // Subsample aux_u to YUV420 chroma resolution
    // This is a simplified version - real implementation more complex

    YUV420Frame {
        y: aux_y,
        u: subsample_to_half(aux_u, ...),
        v: vec![128; (width / 2) * (height / 2)],  // Neutral
        width,
        height,
    }
}
```

**Note:** This simplified version may not match MS spec exactly. Full implementation requires macroblock-level packing per Figure 7 in spec.

**Task 2.3: Reference Implementation Study** (2-3h)
- Study FreeRDP's encoder code (if they have one)
- Or reverse-engineer from decoder
- Document exact packing algorithm
- Create detailed pseudocode

### Phase 3: Dual Encoder (6-10 hours)

**Create:** `src/egfx/avc444_encoder.rs`

**Task 3.1: Encoder Structure** (2-3h)

```rust
pub struct Avc444Encoder {
    /// Encoder for main view (luma + subsampled chroma)
    main_encoder: Avc420Encoder,

    /// Encoder for auxiliary view (additional chroma data)
    aux_encoder: Avc420Encoder,

    /// Configuration
    config: EncoderConfig,

    /// Frame counter
    frame_count: u64,
}

impl Avc444Encoder {
    pub fn new(config: EncoderConfig) -> EncoderResult<Self> {
        // Create two independent H.264 encoders
        // Same configuration for both (bitrate, QP, etc.)
        let main_encoder = Avc420Encoder::new(config.clone())?;
        let aux_encoder = Avc420Encoder::new(config.clone())?;

        Ok(Self {
            main_encoder,
            aux_encoder,
            config,
            frame_count: 0,
        })
    }
}
```

**Task 3.2: Encoding Method** (4-6h)

```rust
pub struct Avc444Frame {
    pub stream1_data: Vec<u8>,  // Main H.264 bitstream
    pub stream2_data: Vec<u8>,  // Auxiliary H.264 bitstream
    pub is_keyframe: bool,
    pub timestamp_ms: u64,
}

impl Avc444Encoder {
    pub fn encode_bgra(
        &mut self,
        bgra: &[u8],
        width: u32,
        height: u32,
        timestamp_ms: u64,
    ) -> EncoderResult<Option<Avc444Frame>> {
        // Step 1: BGRA ‚Üí YUV444
        let (y_444, u_444, v_444) = bgra_to_yuv444(
            bgra,
            width as usize,
            height as usize,
        );

        // Step 2: Decompose to two YUV420 frames
        let main_yuv420 = create_main_view(&y_444, &u_444, &v_444, width, height);
        let aux_yuv420 = create_auxiliary_view(&u_444, &v_444, width, height);

        // Step 3: Encode both streams
        let main_frame = self.main_encoder.encode_yuv420(
            &main_yuv420.to_bgra(),  // Convert YUV420 back to BGRA for OpenH264
            width,
            height,
            timestamp_ms,
        )?;

        let aux_frame = self.aux_encoder.encode_yuv420(
            &aux_yuv420.to_bgra(),
            width,
            height,
            timestamp_ms,
        )?;

        // Step 4: Package
        let Some(stream1) = main_frame else {
            return Ok(None);  // Encoder skipped
        };

        let Some(stream2) = aux_frame else {
            return Ok(None);  // Encoder skipped
        };

        Ok(Some(Avc444Frame {
            stream1_data: stream1.data,
            stream2_data: stream2.data,
            is_keyframe: stream1.is_keyframe,
            timestamp_ms,
        }))
    }
}
```

**Task 3.3: Optimization** (2-4h)
- SIMD for color conversion (AVX2/NEON)
- Parallel encoding of two streams
- Memory pooling for YUV buffers
- Profile and optimize hot paths

### Phase 4: Integration & Testing (8-12 hours)

**Task 4.1: Display Handler Integration** (2-3h)

Modify: `src/server/display_handler.rs`

```rust
// Detect codec from config
let encoder: Box<dyn VideoEncoder> = match config.egfx.codec.as_str() {
    "avc444" => Box::new(Avc444Encoder::new(encoder_config)?),
    "avc420" | _ => Box::new(Avc420Encoder::new(encoder_config)?),
};

// In frame loop:
let encoded = encoder.encode_bgra(&frame_data, width, height, timestamp)?;

// Send based on codec type
match encoded {
    EncodedFrame::Avc444(frame) => {
        egfx_sender.send_avc444_frame(
            surface_id,
            &frame.stream1_data,
            &[Avc420Region::full_frame(width, height, 23)],
            Some(&frame.stream2_data),
            Some(&[Avc420Region::full_frame(width, height, 23)]),
            timestamp_ms as u32,
        ).await?;
    }
    EncodedFrame::Avc420(frame) => {
        // Existing path
    }
}
```

**Task 4.2: Windows Client Testing** (3-4h)
- Configure `codec = "avc444"` in config
- Connect Windows 10/11 client (must support AVC444)
- Verify dual streams received
- Check client successfully decodes
- Compare visual quality vs AVC420

**Task 4.3: Quality Validation** (3-5h)
- Color gradient test (smooth transitions?)
- Text rendering test (sharp colors?)
- Photo/image test (accurate colors?)
- Graphics app test (GIMP, Inkscape)
- Measure color accuracy (Delta-E if possible)

---

## CURRENT IRONRDP AVC444 SUPPORT MATRIX

### What Works NOW ‚úÖ

| Component | Status | Location |
|-----------|--------|----------|
| AVC444 PDU Structures | ‚úÖ Complete | `ironrdp-egfx/src/pdu/avc.rs` |
| Avc444BitmapStream Encode/Decode | ‚úÖ Complete | `ironrdp-egfx/src/pdu/avc.rs` |
| Server send_avc444_frame() | ‚úÖ Complete | `ironrdp-egfx/src/server.rs` |
| Capability Negotiation | ‚úÖ Complete | `ironrdp-egfx/src/server.rs` |
| ZGFX Wrapping | ‚úÖ Complete | `ironrdp-graphics/src/zgfx/` |

### What We Need to Build ‚ùå

| Component | Status | Effort |
|-----------|--------|--------|
| BGRA ‚Üí YUV444 Conversion | ‚ùå Not started | 3-4h |
| YUV444 ‚Üí Dual YUV420 Packing | ‚ùå Not started | 4-6h |
| Avc444Encoder Implementation | ‚ùå Not started | 6-10h |
| Integration & Testing | ‚ùå Not started | 8-12h |

**Total Implementation Effort:** 21-32 hours

---

## ALTERNATIVE APPROACHES RESEARCHED

### Approach A: Dual OpenH264 Encoders (RECOMMENDED)

**What:** Use two separate OpenH264 instances

**Pros:**
- ‚úÖ Uses existing Avc420Encoder code
- ‚úÖ Well-tested OpenH264 library
- ‚úÖ Independent QP control per stream
- ‚úÖ Straightforward implementation

**Cons:**
- ‚ùå 2√ó memory footprint
- ‚ùå 2√ó encoding time (sequential or parallel)
- ‚ùå Complex chroma packing algorithm

**Verdict:** Best approach for initial implementation

### Approach B: x264 Native 4:4:4 Support

**What:** Use x264 library which supports native YUV444 encoding

**Pros:**
- ‚úÖ Native YUV444 support (no packing tricks)
- ‚úÖ Single encoder
- ‚úÖ Better quality (designed for 4:4:4)

**Cons:**
- ‚ùå x264 is GPL (licensing issue)
- ‚ùå Different API to learn
- ‚ùå Another dependency
- ‚ùå Client must decode standard 4:4:4 H.264

**Verdict:** Not viable (licensing + client compatibility)

### Approach C: Hardware Encoder (VAAPI 4:4:4)

**What:** Use GPU encoder with native 4:4:4 support

**Pros:**
- ‚úÖ Fastest encoding
- ‚úÖ Best quality
- ‚úÖ Single encoder

**Cons:**
- ‚ùå Requires VAAPI first
- ‚ùå Hardware dependency
- ‚ùå Still need to pack into dual streams for MS protocol

**Verdict:** Future optimization after software AVC444 works

### Approach D: FFmpeg libavcodec

**What:** Use FFmpeg's H.264 encoder with 4:4:4 support

**Pros:**
- ‚úÖ Powerful, well-tested
- ‚úÖ Can do native 4:4:4
- ‚úÖ Better rate control than OpenH264

**Cons:**
- ‚ùå LGPL licensing (must dynamic link)
- ‚ùå Large dependency
- ‚ùå Complex API
- ‚ùå Still need dual-stream packing for MS protocol

**Verdict:** Possible alternative, but OpenH264 simpler

---

## PREMIUM FEATURE JUSTIFICATION

### Why AVC444 is a Strong Premium Feature

**1. Clear Quality Difference** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Visible to users (smooth gradients, sharp colors)
- Measurable (color accuracy metrics)
- Justifies premium pricing

**2. Target Audience** ‚≠ê‚≠ê‚≠ê‚≠ê
- Graphics professionals (designers, artists)
- CAD/engineering users
- Photo/video editors
- Anyone who needs accurate color

**3. Technical Moat** ‚≠ê‚≠ê‚≠ê‚≠ê
- Complex implementation (dual stream packing)
- Not easily replicated
- Requires deep protocol understanding
- Justifies keeping proprietary

**4. Bandwidth Tradeoff** ‚≠ê‚≠ê‚≠ê
- +30-40% bandwidth vs AVC420
- Only worth it for those who need quality
- Natural segmentation (premium = quality tier)

**5. Competitive Differentiation** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- Most open-source RDP servers: AVC420 only
- Commercial products (Citrix, VMware): Have AVC444
- Positions lamco-rdp-server in commercial tier

### Pricing Strategy Implications

**Free Tier (lamco-rdp-server-community):**
- AVC420 codec (good quality, efficient)
- Suitable for 90% of users

**Premium Tier (lamco-rdp-server-pro):**
- AVC444 codec (excellent color accuracy)
- Targets graphics professionals
- Justifies $X/month or $Y/perpetual license

**Competitive Analysis:**

| Product | AVC444 Support | Pricing |
|---------|----------------|---------|
| **Windows RDS** | ‚úÖ Yes | $X/user/month |
| **Citrix VDI** | ‚úÖ Yes | $$$/user/month |
| **VMware Horizon** | ‚úÖ Yes | $$$/user/month |
| **xrdp** | ‚ùå No | Free |
| **FreeRDP** | ‚úÖ Client only | Free |
| **lamco-rdp-server** | üéØ Premium | Your pricing |

**Value Proposition:** First open-source RDP **server** with AVC444 at accessible pricing.

---

## TECHNICAL RISKS & MITIGATION

### Risk 1: Chroma Packing Complexity

**Risk:** Incorrect pixel ordering breaks reconstruction

**Likelihood:** Medium
**Impact:** High (corruption, wrong colors)

**Mitigation:**
- Study MS spec Figure 7 carefully
- Reference FreeRDP decoder (reverse-engineer)
- Unit test with known patterns
- Pixel-by-pixel validation
- Start with simplified packing, refine later

### Risk 2: OpenH264 Quirks with Fake Luma

**Risk:** Encoder optimizes differently for chroma-as-luma

**Likelihood:** Low
**Impact:** Medium (quality degradation)

**Mitigation:**
- Test with various content types
- Compare bitstream sizes
- May need to disable some encoder optimizations
- Document any workarounds

### Risk 3: Bandwidth Concerns

**Risk:** +30-40% bandwidth may be unacceptable for some users

**Likelihood:** Medium
**Impact:** Low (it's optional premium feature)

**Mitigation:**
- Make codec selectable in config
- Document bandwidth tradeoffs clearly
- Recommend AVC420 for WAN, AVC444 for LAN/quality
- Provide bandwidth estimates per resolution

### Risk 4: Client Compatibility

**Risk:** Not all Windows clients support AVC444

**Likelihood:** Low
**Impact:** Medium (feature not usable)

**Mitigation:**
- Test with Windows 10/11 (should support)
- Capability negotiation (fall back to AVC420)
- Document client requirements
- Provide compatibility matrix

### Risk 5: Implementation Time

**Risk:** Actual effort exceeds estimate (21-32h)

**Likelihood:** Medium
**Impact:** Low (it's worth the investment)

**Mitigation:**
- Phased implementation (test after each phase)
- Accept simplified v1 (refine later)
- Budget extra time for debugging
- Have fallback to AVC420 always

---

## RECOMMENDED IMPLEMENTATION APPROACH

### Phased Development Strategy

**Phase 1: Minimal Viable AVC444** (12-16 hours)
```
Goal: Get SOMETHING working end-to-end

1. Simple BGRA ‚Üí YUV444 conversion
2. Simplified dual-stream packing (may not be perfect)
3. Basic dual encoding
4. Wire up to IronRDP send_avc444_frame()
5. Test with Windows client

Acceptance: Client receives and decodes (even if some color errors)
```

**Phase 2: Spec Compliance** (8-12 hours)
```
Goal: Match MS-RDPEGFX specification exactly

1. Implement macroblock-level packing per spec
2. Study FreeRDP decoder for validation
3. Refine chroma interleaving
4. Test with color accuracy tools

Acceptance: Pixel-perfect match with Windows native RDP
```

**Phase 3: Optimization** (6-10 hours)
```
Goal: Production-ready performance

1. SIMD color conversion (AVX2/NEON)
2. Parallel stream encoding
3. Memory optimization
4. Profile and tune

Acceptance: <30ms total encoding time @ 1080p
```

**Total: 26-38 hours across 3 phases**

### Simplified First Implementation

**For Phase 1, we can use a SIMPLIFIED algorithm:**

```rust
// Main view: Just do standard 4:2:0 subsampling
main_y = y_444;
main_u = subsample_2x2(u_444);
main_v = subsample_2x2(v_444);

// Auxiliary view: Pack remaining chroma naively
// Extract pixels at odd positions
aux_y = extract_odd_pixels(u_444);
aux_u = extract_odd_pixels(v_444);
aux_v = vec![128; size];  // Neutral

// Encode both
stream1 = encode_h264(main_y, main_u, main_v);
stream2 = encode_h264(aux_y, aux_u, aux_v);
```

**This won't be perfect** (won't match spec's macroblock packing exactly) **but:**
- ‚úÖ Will work for basic testing
- ‚úÖ Client can probably decode it
- ‚úÖ Proves the concept
- ‚úÖ Can refine in Phase 2

**Accept some color errors in Phase 1, perfect in Phase 2.**

---

## TESTING STRATEGY

### Test 1: Color Gradient (Basic Quality)

**Setup:**
- Open web browser to gradient generator
- Display RGB gradients (R: 0‚Üí255, G: 0‚Üí255, B: 0‚Üí255)

**AVC420 Result:** Visible color banding in gradients
**AVC444 Target:** Smooth gradients, no banding

**Measurement:** Visual inspection + screenshots

### Test 2: Color Accuracy (Advanced Quality)

**Setup:**
- Display standard color chart (Macbeth ColorChecker)
- Capture via AVC420
- Capture via AVC444
- Compare with reference

**Measurement:**
- Delta-E color difference
- AVC420: Delta-E ~10-15 typical
- AVC444: Delta-E <5 target

### Test 3: Graphics Applications

**Test Cases:**
- GIMP: Color picker, verify RGB values match
- Inkscape: Vector graphics with precise colors
- Firefox: Web graphics and images
- Terminal: Syntax highlighting colors

**Success:** No color shift, accurate rendering

### Test 4: Bandwidth Measurement

**Setup:**
- Static desktop: Measure bandwidth
- Scrolling: Measure bandwidth
- Graphics work: Measure bandwidth

**Comparison:**
- AVC420: Baseline (e.g., 4 Mbps)
- AVC444: Should be ~6 Mbps (+50%)

**Acceptance:** Bandwidth increase acceptable for quality gain

---

## CONFIGURATION STRATEGY

### Config Section (Already Added)

```toml
[egfx]
codec = "avc444"  # Switch from "avc420"
h264_bitrate = 8000  # Higher for better quality
```

### User-Facing Documentation

**When to Use AVC444:**
- ‚úÖ Graphics/design work
- ‚úÖ Photo editing
- ‚úÖ CAD applications
- ‚úÖ Accurate color critical
- ‚úÖ LAN environment (bandwidth available)

**When to Use AVC420:**
- ‚úÖ General desktop use
- ‚úÖ Office applications
- ‚úÖ Web browsing
- ‚úÖ WAN environment (bandwidth limited)
- ‚úÖ Multi-user servers (CPU constrained)

---

## RESEARCH FINDINGS SUMMARY

### elmarco's Work

**Status:** Started EGFX PDU work in PR #648, focused on AVC444
**Outcome:** Handed off to you ("feel free to close this PR once you have one that supersedes it")
**Your PR #1057:** Supersedes his work with complete implementation
**His Repo:** freerdp-rs (Rust bindings to FreeRDP) - last active 2022

### Microsoft Specification

**Document:** [MS-RDPEGFX] Section 2.2.4.5 and 3.3.8.3.2
**Algorithm:** Pack YUV444 into two YUV420 streams using macroblock-level interleaving
**Complexity:** High (requires precise pixel ordering)
**Quality:** Supports optional reverse filter to reduce artifacts

### FreeRDP Implementation

**Decoder:** Complete since 2016
**Encoder:** Unknown (may not exist for server-side)
**Issues:** Some bugs with reverse filter, quality concerns
**Lesson:** Decoder is complex, encoder likely more so

### IronRDP Current State

**Protocol:** 100% complete in your PR #1057
**Encoder:** 0% implemented (our task)
**Readiness:** Protocol ready to use, just need encoder

---

## DECISION POINTS

### Decision 1: Implementation Complexity Level

**Option A: Simplified (Phase 1 only)**
- Naive chroma packing
- May have some color errors
- Fast to implement (12-16h)
- Good enough for testing

**Option B: Spec-Compliant (Phases 1+2)**
- Exact macroblock packing per MS spec
- Pixel-perfect accuracy
- Takes longer (20-28h)
- Production quality

**Option C: Optimized (All 3 phases)**
- Spec-compliant + SIMD + parallel
- Best performance
- Full effort (26-38h)
- Premium feature quality

**Recommendation:** Start with **Option A**, refine to **Option B** if testing shows issues

### Decision 2: Keep Proprietary or Contribute?

**Keep in lamco-rdp-server (Premium):**
- ‚úÖ Commercial differentiation
- ‚úÖ Justifies premium pricing
- ‚úÖ High implementation effort

**Contribute to IronRDP (Open):**
- ‚úÖ Community benefit
- ‚úÖ More users = more testing
- ‚ùå Loses competitive advantage

**Recommendation:** **Keep as premium feature** for lamco-rdp-server

### Decision 3: Priority vs Other Features

**AVC444:** 21-32 hours
**Damage Tracking:** 22-32 hours
**Hardware Encoding:** 28-40 hours

**Which first?**
- AVC444: Most visible quality improvement
- Damage: Most immediate bandwidth savings
- VAAPI: Most scalability benefit

**Recommendation:** **AVC444 first** - highest premium value, clearest differentiation

---

## NEXT STEPS

### Immediate Research Tasks (Completed)

- ‚úÖ elmarco's work history researched
- ‚úÖ IronRDP PR #648 and #1057 analyzed
- ‚úÖ MS-RDPEGFX specification studied
- ‚úÖ FreeRDP implementation reviewed
- ‚úÖ IronRDP current support assessed

### Development Tasks (Ready to Start)

**Task 1:** Implement BGRA ‚Üí YUV444 conversion (3-4h)
**Task 2:** Implement dual-stream packing (4-6h)
**Task 3:** Create Avc444Encoder (6-10h)
**Task 4:** Integration and testing (8-12h)

**Total:** 21-32 hours

### Decision Needed

**Do you want to:**
1. **Start AVC444 implementation now** (I begin with color conversion)
2. **More research first** (study FreeRDP decoder source in detail)
3. **Defer AVC444** (do damage tracking or VAAPI first)
4. **Something else**

---

**Sources:**
- [MS-RDPEGFX AVC444 Specification](https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-rdpegfx/844018a5-d717-4bc9-bddb-8b4d6be5dd3f)
- [YUV420p Stream Combination](https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-rdpegfx/8131c1bc-1af8-4907-a05a-f72f4581160f)
- [FreeRDP AVC444 Implementation](https://github.com/FreeRDP/FreeRDP/commit/5bc333c626f1db493a2c2e3c49d91cc6fb145309)
- [IronRDP PR #648 by elmarco](https://github.com/Devolutions/IronRDP/pull/648)
- [Your IronRDP PR #1057](https://github.com/Devolutions/IronRDP/pull/1057)
- [FreeRDP AVC444 Issues](https://github.com/FreeRDP/FreeRDP/issues/11040)

**READY TO IMPLEMENT - Your call on next steps.**
